# LLM-Based Onboarding Chatbot for TUM  
A conversational assistant powered by Large Language Models (LLMs) to streamline the onboarding experience for new professors, staff, and employees at the Technical University of Munich (TUM).

## Project Overview

This project delivers a smart, AI-based chatbot designed to help new employees and faculty members at TUM get quick, accurate answers to onboarding-related questions. It retrieves real-time institutional data and personalizes responses based on department, role, and user context.

Key onboarding support includes:
- Office and equipment requests  
- Department-specific procedures  
- Administrative contact lookups  
- Access to forms, guidelines, and internal links  

## Features

âœ… Natural Language Understanding for Vague or Incomplete Questions  
âœ… Personalization Based on Department and Role  
âœ… Institutional Data Retrieval from TUMwiki and TUMonline  
âœ… Clarifying Follow-up Questions to Improve Accuracy  
âœ… Chat Interface with Quick Action Links and Document Suggestions  

## Tech Stack

- **Frontend:** React (for web interface)  
- **Backend:** Python (FastAPI or Flask)  
- **LLM Integration:** OpenAI GPT-4 (via API)  
- **Retrieval System:** LangChain or LlamaIndex (RAG pipeline)  
- **Vector DB:** FAISS / Chroma / Pinecone  
- **Hosting:** Render, Vercel, or TUM internal servers  

## Installation & Setup

To run this project locally:

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/miglios2912/Group-19---Gen-AI
cd tum-onboarding-chatbot
```

### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
# or for frontend:
npm install
```

### 3ï¸âƒ£ Set Up Environment Variables
Create a `.env` file:
```
OPENAI_API_KEY=your_api_key_here
VECTOR_DB_PATH=path_to_your_vector_store
```

### 4ï¸âƒ£ Start the Backend
```bash
python app.py
```

### 5ï¸âƒ£ Start the Frontend (if using React)
```bash
npm start
```

## How It Works

1ï¸âƒ£ User asks a natural-language question (e.g., â€œHow do I get ...?â€)  
2ï¸âƒ£ The chatbot uses retrieval-augmented generation (RAG) to fetch relevant onboarding info  
3ï¸âƒ£ If needed, it asks follow-up questions (e.g., â€œWhich department are you in?â€)  
4ï¸âƒ£ LLM generates a personalized, concise response with optional links or forms  
5ï¸âƒ£ The user receives tailored onboarding guidance in seconds  

## Folder Structure

```
tum-onboarding-chatbot/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                 # Main FastAPI/Flask backend
â”‚   â”œâ”€â”€ data/                  # Onboarding docs and embeddings
â”‚   â””â”€â”€ retrieval/             # Vector DB setup and query logic
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/        # Chat UI, buttons, etc.
â”‚   â”‚   â”œâ”€â”€ App.js
â”‚   â”‚   â””â”€â”€ index.js
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

## Future Improvements

ğŸ”¹ **Authentication Integration** â€“ Enable user-specific history and settings  
ğŸ”¹ **Multilingual Support** â€“ Serve responses in German or English  
ğŸ”¹ **Advanced Analytics** â€“ Log user behavior to improve chatbot responses  
ğŸ”¹ **Slack/MS Teams Integration** â€“ Allow usage within internal TUM platforms  

## ğŸ“© Contact

For questions, feedback, or collaboration opportunities:  
ğŸ“§ Email: simone.miglio@tum.de
